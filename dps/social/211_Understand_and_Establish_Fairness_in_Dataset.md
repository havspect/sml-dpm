---
title: Understand and Establish Fairness in Dataset
lang: en-US
sustainability-dimension: Social
ml-development-phase: Data Collection and Preparation 
ml-development-stakeholders: 
    - D
    - M
    - AT
written-by: havspect
---

<script setup>
import DPOverview from '../../components/DPOverview.vue'
</script>


# {{ $frontmatter.title }} <Badge type="tip">new</Badge>

## Overview
<DPOverview />

## Description
“Understand and Establish Fairness in Dataset” describes the data analysis steps to identify social unfairness. Before ML developers can avoid potential fairness obstacles within a dataset, they first must understand where unfairness can occur (Holstein et al., 2019; Tang et al., 2023). Understanding a dataset and identifying possible areas of unfairness requires data plotting, exchanges with domain experts, and even the design of proxy variables to identify relationships and reasons for social biases (Ferrara, 2023; Van Giffen et al., 2022). Gu et al. (2021) recommend using interactive tools for data analysis since they provide a better understanding of data. After understanding unfairness sources, ML developers can actively initiate mitigation strategies (Van Giffen et al., 2022). 

## Real-world examples 


## Sources 

- 